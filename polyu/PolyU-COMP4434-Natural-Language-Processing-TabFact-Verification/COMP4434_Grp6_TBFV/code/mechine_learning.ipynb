{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T08:47:13.724503Z",
     "start_time": "2024-12-14T08:47:13.718137Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import re\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd39a27c75608a70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T08:47:58.272832Z",
     "start_time": "2024-12-14T08:47:58.256638Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/hpc/puhome/23096373d'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20115ea446abbd9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T08:50:54.814817Z",
     "start_time": "2024-12-14T08:50:54.360812Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the TSV data\n",
    "data_path = './dataset/tsv_data_horizontal/train.tsv'\n",
    "complex_test_path = './dataset/tsv_data_horizontal/complex_test.tsv'\n",
    "simple_test_path = './dataset/tsv_data_horizontal/simple_test.tsv'\n",
    "small_test_path = './dataset/tsv_data_horizontal/small_test.tsv'\n",
    "test_path = './dataset/tsv_data_horizontal/test.tsv'\n",
    "data = pd.read_csv(data_path, sep='\\t', header=None).values\n",
    "complex_test_data = pd.read_csv(complex_test_path, sep='\\t', header=None).values\n",
    "simple_test_data = pd.read_csv(simple_test_path, sep='\\t', header=None).values\n",
    "small_test_data = pd.read_csv(small_test_path, sep='\\t', header=None).values\n",
    "test_data = pd.read_csv(test_path, sep='\\t', header=None).values\n",
    "# Load data for BERT-extracted feature\n",
    "statement_features_path = r\"./dataset/bert_feature_data/statement_features_train.npy\"\n",
    "table_features_path = r\"./dataset/bert_feature_data/table_feature_train.npy\"\n",
    "labels_path = r\"./dataset/bert_feature_data/labels_train.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5df9f9db90915c49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T08:50:59.807411Z",
     "start_time": "2024-12-14T08:50:59.791998Z"
    }
   },
   "outputs": [],
   "source": [
    "#-----------------Data Preprocessing-----------------\n",
    "# Clean 'row x is:' in table\n",
    "def clean_out_sub_table(tsv_data):\n",
    "    #table_texts_first = [\" \".join(row[3:-2]) for row in tsv_data]\n",
    "    table_texts_first = []\n",
    "    for row in tsv_data:\n",
    "        row[3] = re.sub(r'\\(.*?\\)','',str(row[3]))\n",
    "        if row[3] != 'nan':\n",
    "            table_texts_first.append(\" \".join(row[2:-2]))\n",
    "        else:\n",
    "            table_texts_first.append(row[2])\n",
    "    table_texts_second = [re.sub(r'\\. (.*?) :', ',', row) for row in table_texts_first]\n",
    "    # print(table_texts_second[0])\n",
    "    table_texts_final = []\n",
    "\n",
    "    for row in table_texts_second:\n",
    "        intermediate = row.split(\" : \")\n",
    "        if len(intermediate) > 1:\n",
    "            table_texts_final.append(intermediate[1])\n",
    "        else:\n",
    "            table_texts_final.append(intermediate[0])\n",
    "\n",
    "    return table_texts_final\n",
    "\n",
    "# Convert data into required format\n",
    "def preprocess_tsv_data(tsv_data):\n",
    "    # Concatenate table-related columns into a single string for each row\n",
    "    # Starting from column 3\n",
    "    table_texts = clean_out_sub_table(tsv_data)\n",
    "    statements = tsv_data[:, -2]\n",
    "    labels = tsv_data[:, -1].astype(int)\n",
    "    return table_texts, statements, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d5e8c4bcaa40789",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T08:51:02.728251Z",
     "start_time": "2024-12-14T08:51:02.177949Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample table text: brazil scorers is friedenreich  , neco  , haroldo , brazil scorers is heitor , am√≠lcar , millon , brazil scorers is neco  , brazil scorers is friedenreich , brazil scorers is haroldo , arlindo  .\n",
      "Sample statement: haroldo be mention as a brazil scorer for 2 different game\n",
      "Sample label: 1\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the TSV data\n",
    "table_texts, statements, labels = preprocess_tsv_data(data)\n",
    "\n",
    "# Print a sample test case\n",
    "print(\"Sample table text:\", table_texts[0])\n",
    "print(\"Sample statement:\", statements[0])\n",
    "print(\"Sample label:\", labels[0])\n",
    "\n",
    "#-----------------TF-IDF Feature Extraction -----------------\n",
    "vectorizer = TfidfVectorizer(max_features=500)\n",
    "table_features = vectorizer.fit_transform(table_texts)\n",
    "statement_features = vectorizer.transform(statements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9d25fcbbf08ae64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T08:51:05.256843Z",
     "start_time": "2024-12-14T08:51:04.902736Z"
    }
   },
   "outputs": [],
   "source": [
    "similarities = cosine_similarity(table_features, statement_features)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "636ad0af69bd700e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T08:51:06.007582Z",
     "start_time": "2024-12-14T08:51:06.000197Z"
    }
   },
   "outputs": [],
   "source": [
    "# # -----------------Feature Extraction with Word2Vec-----------------\n",
    "def get_average_word2vec(texts, model, vector_size):\n",
    "    \"\"\"\n",
    "    Convert each text into a vector by averaging the Word2Vec embeddings of its words.\n",
    "\n",
    "    Parameters:\n",
    "    texts: List of tokenized texts.\n",
    "    model: Trained Word2Vec model.\n",
    "    vector_size: Size of the word embeddings.\n",
    "\n",
    "    Returns:\n",
    "    Array of vectors representing each text.\n",
    "    \"\"\"\n",
    "    features = np.zeros((len(texts), vector_size))\n",
    "    for i, tokens in enumerate(texts):\n",
    "        word_vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "        if word_vectors:\n",
    "            features[i] = np.mean(word_vectors, axis=0)  # Average embeddings\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98ca29933fee33fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(similarities, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53d5206c8d71be68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T08:51:26.549874Z",
     "start_time": "2024-12-14T08:51:26.528338Z"
    }
   },
   "outputs": [],
   "source": [
    "#-----------------Cross-Validation Function-----------------\n",
    "def cross_validate_model(model, X, y, k=5, word_to_vec=False, is_regression=False):\n",
    "    \"\"\"\n",
    "    Perform K-Fold Cross-Validation for a given model.\n",
    "\n",
    "    Parameters:\n",
    "    model: The machine learning model (e.g., LogisticRegression, Lasso, SVC).\n",
    "    X: Feature matrix.\n",
    "    y: Labels.\n",
    "    k: Number of folds (default is 5).\n",
    "    is_regression: Whether the model is a regression model (default is False).\n",
    "\n",
    "    Returns:\n",
    "    average_accuracy: The average accuracy across all folds.\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    accuracies = []\n",
    "    if not word_to_vec:\n",
    "        X = X.reshape(-1, 1)\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        model.fit(X_train, y_train)  # Train the model\n",
    "        y_pred = model.predict(X_test)  # Predict on test data\n",
    "\n",
    "        # If regression, convert predictions to discrete labels\n",
    "        if is_regression:\n",
    "            y_pred = np.round(y_pred).astype(int)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "        print(f\"Fold Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "    average_accuracy = sum(accuracies) / k\n",
    "    return average_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82c54adc99102caa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T08:51:31.094765Z",
     "start_time": "2024-12-14T08:51:31.082509Z"
    }
   },
   "outputs": [],
   "source": [
    "#-----------------Evaluate Method------------------\n",
    "def model_eval(model,this_data,word_to_vec = False,is_regression=False):\n",
    "    table_texts_test, statements_test, labels_test = preprocess_tsv_data(this_data)\n",
    "    labels_test = labels_test.astype(int)\n",
    "    if word_to_vec:\n",
    "        tokenized_table_texts_test = [text.split() for text in table_texts_test]\n",
    "        tokenized_statements_test = [text.split() for text in statements_test]\n",
    "\n",
    "        # Train a Word2Vec model\n",
    "        w2v_model_test = Word2Vec(sentences=tokenized_table_texts_test + tokenized_statements_test, vector_size=50, window=5,\n",
    "                             min_count=1, workers=4)\n",
    "        table_features_w2v_test = get_average_word2vec(tokenized_table_texts_test, w2v_model_test, vector_size=50)\n",
    "        statement_features_w2v_test = get_average_word2vec(tokenized_statements_test, w2v_model_test, vector_size=50)\n",
    "        similarities_test = np.hstack([table_features_w2v_test, statement_features_w2v_test])\n",
    "        y_pred = model.predict(similarities_test)\n",
    "    else:\n",
    "        vectorizer0 = TfidfVectorizer(max_features=500)\n",
    "        table_features_test = vectorizer0.fit_transform(table_texts_test)\n",
    "        statement_features_test = vectorizer0.transform(statements_test)\n",
    "        test_similarities = cosine_similarity(table_features_test, statement_features_test)[0]\n",
    "        y_pred = model.predict(test_similarities.reshape(-1,1))\n",
    "    if is_regression:\n",
    "        y_pred = np.round(y_pred).astype(int)\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(labels_test, y_pred)\n",
    "    return accuracy\n",
    "    #print(f\"Prediction Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "    # # Generate a classification report\n",
    "    # report = classification_report(labels_test, y_pred)\n",
    "    # print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb101c7fae718feb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T08:51:37.798137Z",
     "start_time": "2024-12-14T08:51:34.318277Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lasso Regression Cross-Validation:\n",
      "Fold Accuracy: 0.55\n",
      "Fold Accuracy: 0.55\n",
      "Fold Accuracy: 0.55\n",
      "Fold Accuracy: 0.56\n",
      "Fold Accuracy: 0.54\n",
      "Average Accuracy for Lasso Regression: 0.55\n",
      "test.tsv: 0.50\n",
      "simple_test.tsv: 0.51\n",
      "complex_test.tsv: 0.50\n",
      "small_test.tsv: 0.49\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#-----------------Lasso Regression-----------------\n",
    "# Train a Lasso Regression model\n",
    "print(\"\\nLasso Regression Cross-Validation:\")\n",
    "lasso_model = Lasso(alpha=0.1)\n",
    "lasso_avg_accuracy = cross_validate_model(lasso_model, similarities, labels, k=5, word_to_vec=False,is_regression=True)\n",
    "print(f\"Average Accuracy for Lasso Regression: {lasso_avg_accuracy:.2f}\")\n",
    "print(f\"test.tsv: {model_eval(lasso_model,test_data,word_to_vec=False,is_regression=True):.2f}\")\n",
    "print(f\"simple_test.tsv: {model_eval(lasso_model,simple_test_data,word_to_vec=False,is_regression=True):.2f}\")\n",
    "print(f\"complex_test.tsv: {model_eval(lasso_model,complex_test_data,word_to_vec=False,is_regression=True):.2f}\")\n",
    "print(f\"small_test.tsv: {model_eval(lasso_model,small_test_data,word_to_vec=False,is_regression=True):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afb0ab139b4e3f70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T08:52:16.361719Z",
     "start_time": "2024-12-14T08:52:03.837319Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Support Vector Machine Cross-Validation:\n",
      "Fold Accuracy: 0.55\n",
      "Fold Accuracy: 0.55\n",
      "Fold Accuracy: 0.55\n",
      "Fold Accuracy: 0.56\n",
      "Fold Accuracy: 0.54\n",
      "Average Accuracy for Support Vector Machine: 0.55\n",
      "test.tsv: 0.50\n",
      "complex_test.tsv: 0.50\n",
      "simple_test.tsv: 0.51\n",
      "small_test.tsv: 0.49\n"
     ]
    }
   ],
   "source": [
    "#-----------------Support Vector Machine-----------------\n",
    "print(\"\\nSupport Vector Machine Cross-Validation:\")\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_avg_accuracy = cross_validate_model(svm_model, similarities, labels, k=5,word_to_vec=False)\n",
    "print(f\"Average Accuracy for Support Vector Machine: {svm_avg_accuracy:.2f}\")\n",
    "print(f\"test.tsv: {model_eval(svm_model,test_data,word_to_vec=False):.2f}\")\n",
    "print(f\"complex_test.tsv: {model_eval(svm_model,complex_test_data,word_to_vec=False):.2f}\")\n",
    "print(f\"simple_test.tsv: {model_eval(svm_model,simple_test_data,word_to_vec=False):.2f}\")\n",
    "print(f\"small_test.tsv: {model_eval(svm_model,small_test_data,word_to_vec=False):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46e734007fda1d5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T08:52:26.058172Z",
     "start_time": "2024-12-14T08:52:22.441078Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree Classifier Cross-Validation:\n",
      "Fold Accuracy: 0.55\n",
      "Fold Accuracy: 0.55\n",
      "Fold Accuracy: 0.55\n",
      "Fold Accuracy: 0.56\n",
      "Fold Accuracy: 0.54\n",
      "Average Accuracy for Decision Tree Classifier: 0.55\n",
      "test.tsv: 0.50\n",
      "complex_test.tsv: 0.50\n",
      "simple_test.tsv: 0.51\n",
      "small_test.tsv: 0.50\n"
     ]
    }
   ],
   "source": [
    "#-----------------Decision Tree Classifier-----------------\n",
    "print(\"\\nDecision Tree Classifier Cross-Validation:\")\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_avg_accuracy = cross_validate_model(dt_model, similarities, labels, k=5,word_to_vec=False)\n",
    "print(f\"Average Accuracy for Decision Tree Classifier: {dt_avg_accuracy:.2f}\")\n",
    "print(f\"test.tsv: {model_eval(dt_model,test_data,word_to_vec=False):.2f}\")\n",
    "print(f\"complex_test.tsv: {model_eval(dt_model,complex_test_data,word_to_vec=False):.2f}\")\n",
    "print(f\"simple_test.tsv: {model_eval(dt_model,simple_test_data,word_to_vec=False):.2f}\")\n",
    "print(f\"small_test.tsv: {model_eval(dt_model,small_test_data,word_to_vec=False):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dcacb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
