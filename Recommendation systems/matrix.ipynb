{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/module2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5ZI68kc50pX",
        "outputId": "1b148725-7351-49a7-f43c-7d17aa85399f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Load data\n",
        "user_reviews = pd.read_csv('user_reviews.csv')\n",
        "movie_genres = pd.read_csv('movie_genres.csv')\n",
        "\n",
        "# Preprocess data\n",
        "user_reviews_cleaned = user_reviews.iloc[:, 2:].values  # User-movie ratings\n",
        "user_reviews_cleaned = user_reviews_cleaned / np.max(user_reviews_cleaned)  # Normalize ratings\n",
        "\n",
        "movie_genres_cleaned = movie_genres.iloc[:, 2:].values  # Movie-genre matrix\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "user_reviews_tensor = torch.tensor(user_reviews_cleaned, dtype=torch.float32)  # Shape: (num_users, num_movies)\n",
        "movie_genres_tensor = torch.tensor(movie_genres_cleaned, dtype=torch.float32)  # Shape: (num_movies, num_genres)\n",
        "\n",
        "# Dimensions\n",
        "num_users = user_reviews_tensor.shape[0]  # Number of users\n",
        "num_movies = user_reviews_tensor.shape[1]  # Number of movies\n",
        "num_genres = movie_genres_tensor.shape[1]  # Number of genres\n",
        "\n",
        "# Mask for observed ratings\n",
        "mask = (user_reviews_tensor > 0).float()  # 1 for observed ratings, 0 for missing\n",
        "\n",
        "# Define the neural network with two hidden layers\n",
        "class RecommendationNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size1,output_size):\n",
        "        super(RecommendationNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size1)  # First hidden layer\n",
        "        self.fc2 = nn.Linear(hidden_size1, output_size)  # Output layer (predict ratings)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)  # Apply ReLU activation for the first hidden layer\n",
        "        x = self.fc2(x) # Output predicted ratings\n",
        "        return x\n",
        "\n",
        "# Hyperparameters\n",
        "hidden_size1 = 32 # Number of neurons in the first hidden layer\n",
        "\n",
        "learning_rate = 0.05\n",
        "reg_param = 0.001  # Regularization parameter\n",
        "num_epochs = 5000\n",
        "\n",
        "# Initialize the model\n",
        "input_size = num_genres * num_movies\n",
        "output_size = num_users * num_movies\n",
        "model = RecommendationNN(input_size, hidden_size1,output_size)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.MSELoss(reduction='sum')  # Mean squared error loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=reg_param)  # L2 regularization via weight_decay\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    # Flatten movie_genres_tensor to match input size\n",
        "    flattened_input = movie_genres_tensor.reshape(1, -1)  # Shape: (1, num_genres * num_movies)\n",
        "\n",
        "    # Forward pass: predict ratings\n",
        "    predictions = model(flattened_input)  # Shape: (1, num_users * num_movies)\n",
        "\n",
        "    # Reshape predictions to match the shape of user_reviews_tensor\n",
        "    predictions_reshaped = predictions.view(num_users, num_movies)  # Shape: (num_users, num_movies)\n",
        "\n",
        "    # Compute the error only for observed ratings\n",
        "    error = (user_reviews_tensor - predictions_reshaped) * mask  # Shape: (num_users, num_movies)\n",
        "\n",
        "    # Compute the loss (MSE for observed ratings)\n",
        "    loss = torch.sum(error**2)\n",
        "\n",
        "    # Backward pass and weight update\n",
        "    optimizer.zero_grad()  # Clear the gradients\n",
        "    loss.backward()  # Compute gradients\n",
        "    optimizer.step()  # Update weights\n",
        "\n",
        "    # Print the loss every 50 epochs\n",
        "    if (epoch + 1) % 50 == 0:\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "    if loss<0.1:\n",
        "      break\n",
        "model_path = \"recommendation_model.pth\"\n",
        "torch.save(model.state_dict(), model_path)\n",
        "print(f\"Model saved to {model_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3jNoYGiJ8H9",
        "outputId": "1b9d0eb5-73cd-45db-b0be-92d7f1e363cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50/5000, Loss: 578147.6250\n",
            "Epoch 100/5000, Loss: 9016.0947\n",
            "Epoch 150/5000, Loss: 1669.9355\n",
            "Epoch 200/5000, Loss: 1382.2190\n",
            "Epoch 250/5000, Loss: 1239.6235\n",
            "Epoch 300/5000, Loss: 1098.4055\n",
            "Epoch 350/5000, Loss: 961.9930\n",
            "Epoch 400/5000, Loss: 833.1893\n",
            "Epoch 450/5000, Loss: 713.8941\n",
            "Epoch 500/5000, Loss: 605.2703\n",
            "Epoch 550/5000, Loss: 507.8827\n",
            "Epoch 600/5000, Loss: 421.8181\n",
            "Epoch 650/5000, Loss: 346.7896\n",
            "Epoch 700/5000, Loss: 282.2308\n",
            "Epoch 750/5000, Loss: 227.3782\n",
            "Epoch 800/5000, Loss: 181.3426\n",
            "Epoch 850/5000, Loss: 143.1699\n",
            "Epoch 900/5000, Loss: 111.8908\n",
            "Epoch 950/5000, Loss: 86.5591\n",
            "Epoch 1000/5000, Loss: 66.2810\n",
            "Epoch 1050/5000, Loss: 50.2348\n",
            "Epoch 1100/5000, Loss: 37.6823\n",
            "Epoch 1150/5000, Loss: 27.9747\n",
            "Epoch 1200/5000, Loss: 20.5527\n",
            "Epoch 1250/5000, Loss: 14.9428\n",
            "Epoch 1300/5000, Loss: 10.7507\n",
            "Epoch 1350/5000, Loss: 7.6537\n",
            "Epoch 1400/5000, Loss: 5.3919\n",
            "Epoch 1450/5000, Loss: 3.7588\n",
            "Epoch 1500/5000, Loss: 2.5932\n",
            "Epoch 1550/5000, Loss: 1.7706\n",
            "Epoch 1600/5000, Loss: 1.1967\n",
            "Epoch 1650/5000, Loss: 0.8008\n",
            "Epoch 1700/5000, Loss: 0.5308\n",
            "Epoch 1750/5000, Loss: 0.3486\n",
            "Epoch 1800/5000, Loss: 0.2270\n",
            "Epoch 1850/5000, Loss: 0.1467\n",
            "Model saved to recommendation_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "header = user_reviews.columns.tolist()[2:]\n",
        "\n",
        "first_column = user_reviews.iloc[:, 1]\n",
        "name = first_column.to_numpy()\n",
        "\n",
        "# Predict ratings for all users and movies\n",
        "with torch.no_grad():\n",
        "    flattened_input = movie_genres_tensor.reshape(1, -1)  # Shape: (1, num_genres * num_movies)\n",
        "    predictions = model(flattened_input)  # Shape: (1, num_users * num_movies)\n",
        "    predictions_reshaped = predictions.view(num_users, num_movies)  # Shape: (num_users, num_movies)\n",
        "\n",
        "\n",
        "# Recommendations for the first 5 users\n",
        "recommendations = {}\n",
        "for user_idx in range(5):  # First 5 users\n",
        "    user_ratings = user_reviews_tensor[user_idx]  # Actual ratings by the user\n",
        "    predicted_ratings = predictions_reshaped[user_idx]  # Predicted ratings by the model\n",
        "\n",
        "    # Mask already rated movies\n",
        "    unrated_mask = user_ratings == 0  # True for movies not rated by the user\n",
        "    predicted_ratings = predicted_ratings * unrated_mask  # Set scores for rated movies to 0\n",
        "\n",
        "    # Get the indices of the top 5 movies\n",
        "    recommended_movie_indices = torch.argsort(predicted_ratings, descending=True)[:5]\n",
        "\n",
        "    # Map indices to movie names\n",
        "    recommended_movies = [header[idx] for idx in recommended_movie_indices]\n",
        "    recommendations[user_idx] = recommended_movies\n",
        "\n",
        "# Print recommendations\n",
        "for user_idx, movie_list in recommendations.items():\n",
        "    print(f\"{name[user_idx]}: {movie_list}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c656fb0d-3ef6-4e9f-8289-f33cef5f8fa8",
        "id": "wd8yOPtRpnVI"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vincent: ['Sugar Hill', 'Dinner for Schmucks', 'Elmer Gantry', 'Metropolitan', 'Dumb and Dumber To']\n",
            "Edgar: ['Rollerball', 'Pet Sematary', 'Pretty Woman', 'Blade II', 'Multiplicity']\n",
            "Addilyn: ['Dumb & Dumber', 'Firewall', 'Flushed Away', 'Mi America', 'Jack Reacher']\n",
            "Marlee: ['Middle of Nowhere', 'Ted 2', 'The Story of Us', 'Pootie Tang', 'The Heart of Me']\n",
            "Javier: ['Just My Luck', 'Machete', 'House of 1000 Corpses', 'Dear John', 'Once in a Lifetime: The Extraordinary Story of the New York Cosmos']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2501f0fa-79a5-4bb7-fdf4-e559d6ef6f51",
        "id": "1EQKVvPwpkjT"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50/5000, Loss: 1168503.7500\n",
            "Epoch 100/5000, Loss: 26529.5371\n",
            "Epoch 150/5000, Loss: 1503.5192\n",
            "Epoch 200/5000, Loss: 1339.9778\n",
            "Epoch 250/5000, Loss: 1202.4587\n",
            "Epoch 300/5000, Loss: 1065.8695\n",
            "Epoch 350/5000, Loss: 933.8777\n",
            "Epoch 400/5000, Loss: 809.2027\n",
            "Epoch 450/5000, Loss: 693.6890\n",
            "Epoch 500/5000, Loss: 588.4667\n",
            "Epoch 550/5000, Loss: 494.0864\n",
            "Epoch 600/5000, Loss: 410.6362\n",
            "Epoch 650/5000, Loss: 337.8440\n",
            "Epoch 700/5000, Loss: 275.1679\n",
            "Epoch 750/5000, Loss: 221.8756\n",
            "Epoch 800/5000, Loss: 177.1134\n",
            "Epoch 850/5000, Loss: 139.9644\n",
            "Epoch 900/5000, Loss: 109.4957\n",
            "Epoch 950/5000, Loss: 84.7959\n",
            "Epoch 1000/5000, Loss: 65.0031\n",
            "Epoch 1050/5000, Loss: 49.3235\n",
            "Epoch 1100/5000, Loss: 37.0438\n",
            "Epoch 1150/5000, Loss: 27.5357\n",
            "Epoch 1200/5000, Loss: 20.2570\n",
            "Epoch 1250/5000, Loss: 14.7481\n",
            "Epoch 1300/5000, Loss: 10.6258\n",
            "Epoch 1350/5000, Loss: 7.5761\n",
            "Epoch 1400/5000, Loss: 5.3454\n",
            "Epoch 1450/5000, Loss: 3.7323\n",
            "Epoch 1500/5000, Loss: 2.5790\n",
            "Epoch 1550/5000, Loss: 1.7638\n",
            "Epoch 1600/5000, Loss: 1.1941\n",
            "Epoch 1650/5000, Loss: 0.8004\n",
            "Epoch 1700/5000, Loss: 0.5313\n",
            "Epoch 1750/5000, Loss: 0.3495\n",
            "Epoch 1800/5000, Loss: 0.2279\n",
            "Epoch 1850/5000, Loss: 0.1474\n",
            "Epoch 1900/5000, Loss: 0.0947\n",
            "Epoch 1950/5000, Loss: 0.0607\n",
            "Epoch 2000/5000, Loss: 1485756.0000\n",
            "Epoch 2050/5000, Loss: 325.8176\n",
            "Epoch 2100/5000, Loss: 45.1243\n",
            "Epoch 2150/5000, Loss: 17.7613\n",
            "Epoch 2200/5000, Loss: 9.2216\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-ea6d08f46b76>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Clear the gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Compute gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Update weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;31m# Print the loss every 50 epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                             )\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    221\u001b[0m             )\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    224\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mmaybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdisabled_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_fallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m     func(\n\u001b[0m\u001b[1;32m    785\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;31m# Lastly, switch back to complex view\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "3e13d8b5-85ce-4c46-c876-45ecda42b4e6",
        "id": "N9R44bWbOMgQ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (600) must match the size of tensor b (2000) at non-singleton dimension 0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-2dff23628b84>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# Compute the error only for observed ratings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0muser_reviews_tensor\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmask\u001b[0m  \u001b[0;31m# Transpose predictions to match user-movie shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;31m# Compute the loss (MSE for observed ratings)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (600) must match the size of tensor b (2000) at non-singleton dimension 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y-pRGH38KW2V"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}